// Pre-trained Models for Natural Language Processing: A Survey
// -----------------
// Question Answering
{
    "Paper_ID": 1,
    "Paper_Title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "Background": "the background of the article revolves around the need for a language representation model that can effectively capture bidirectional context and achieve state-of-the-art performance on various natural language processing tasks.",
    "Scope": "Question Answering,Language Inference,Natural Language Processing Tasks,Text Generation,Feature-based Approaches,Fine-tuning,Multitask Training,General Language Representation ",
    "Approach": "BERT pretrains bidirectional language representations from unlabeled text, facilitating fine-tuning for various tasks with minimal changes. Through a masked language model and feature-based approach, it achieves competitive results with simple modifications.",
    "Model": "BERT,Transformer",
    "Dataset": "the main datasets mentioned in the paper are GLUE, SQuAD, MNLI, and SWAG",
    "Result": "BERT excels across eleven NLP tasks, elevating GLUE score to 80.5% (+7.7%), MNLI accuracy to 86.7% (+4.6%), and SQuAD v1.1 F1 to 93.2 (+1.5 points)."
}
{
    "Paper_ID": 2,
    "Paper_Title": "Retrospective Reader for Machine Reading Comprehension",
    "Background": "The article introduces Retro-Reader for MRC, blending sketchy and intensive reading. It outperforms baselines on SQuAD2.0 and NewsQA, emphasizing the vital role of answer verification in MRC tasks.",
    "Scope": "Article explores MRC with unanswerable questions. ",
    "Approach": "The Retro-Reader integrates two stages of reading and verification strategies: sketchy reading and intensive reading.Sketchy reading involves briefly investigating the overall interactions between the passage and question to yield an initial judgment.Intensive reading is used to verify the answer and give the final prediction.",
    "Model": "BERT, ALBERT, and ELECTRA.",
    "Dataset": "The Retro-Reader model proposed in the article is evaluated on these two benchmark MRC challenge datasets, SQuAD2.0 and NewsQA",
    "Result": "The proposed Retro-Reader model achieved new state-of-the-art results on the benchmark MRC challenge datasets, SQuAD2.0 and NewsQA."
}
{
    "Paper_ID": 3,
    "Paper_Title": "Technical report on Conversational Question Answering",
    "Background": "Many models for the CoQA task were based on BERT previously, but until the authors undertook this work, no models based on RoBERTa had been proposed.",
    "Scope": "Used for solving Conversational Question-Answering (CQA) tasks.",
    "Approach": "The researchers added small perturbations at the word embedding layer to create adversarial examples and utilized knowledge distillation techniques to use the outputs of the teacher model as training targets for the student model. Additionally, the paper also introduces an ensemble strategy based on genetic algorithms. ",
    "Model": "BERT, RoBERTa",
    "Dataset": "CoQA",
    "Result": "The system outperforms the current state-of-the-art single model on the CoQA test set, leading by a 2.6% absolute improvement in F1 score, and achieves a score of 90.7 after ensemble."
}
{
    "Paper_ID": 4,
    "Paper_Title": "Select, Answer and Explain: Interpretable Multi-Hop Reading Comprehension over Multiple Documents",
    "Background": "This paper aims to tackle challenges in multi-hop multi-document QA tasks by constructing a model to identify supporting sentences and improve system interpretability, enhancing performance and user experience.",
    "Scope": "Multi-hop multi-document QA (Question Answering) tasks, Graph Neural Network (GNN) applied to QA, Explainable QA, proposed SAE system.",
    "Approach": "The SAE system achieves sentence-level prediction by combining techniques such as Graph Neural Network, Hybrid Attention Pooling Mechanism, Multi-task Learning, and Document Selection.",
    "Model": "BERT, GNN, Interpretable Reasoning Network",
    "Dataset": "HotpotQA",
    "Result": "Evaluated on the HotpotQA dataset, the SAE system achieves an Exact Match (EM) score of 37.07, an F1 score of 66.12, a combined EM and F1 score of 51.18, and a joint EM and F1 score of 67.73. Compared to other models such as the baseline and DFGN, the SAE system demonstrates superior performance. Specifically, DFGN scores 30.09 on EM and 58.61 on F1, while the baseline model scores 8.80 on EM and 20.91 on F1."
}
// Sentiment Analysis
{
    "Paper_ID": 5,
    "Paper_Title": "An Investigation of Transfer Learning-Based Sentiment Analysis in Japanese",
    "Background": "This study mainly discusses the Japanese sentiment analysis method based on transfer learning.",
    "Scope": "Sentiment Analysis",
    "Approach": "\nThis article mentions the methods of BERT and ULMFiT models based on transfer learning, and fine-tunes the models on multiple datasets.",
    "Model": "ELMo, ULMFiT and BERT",
    "Dataset": "Rakuten product review dataset and Yahoo movie review dataset",
    "Result": "The BERT and ULMFiT models based on transfer learning perform better than the specialized task model BCN+ELMo. Specifically, the error rate of BCN+ELMo is 10.24%, while ULMFiT is 4.45% and BERT is 4.68%."
}
{
    "Paper_ID": 6,
    "Paper_Title": "SentiLARE: Sentiment-Aware Language Representation Learning with Linguistic Knowledge",
    "Background": "SentiLARE is an innovative pre-trained language representation model specifically designed to improve the performance of sentiment analysis tasks.",
    "Scope": "understanding of emotions in text",
    "Approach": "SentiLARE uses SentiWordNet to obtain the sentiment scores of different meanings for each word, and determines the weight of each meaning through a context-aware attention mechanism, thereby assigning a more precise emotional polarity to the word.",
    "Model": "BERT, LA-MLM",
    "Dataset": "SST, IMDB, MR, Yelp-2, Yelp-5",
    "Result": "SentiLARE achieved good performance on various tasks, outperforming general pre-trained models, task-specific pre-trained models, and task-specific models without pre-training."
}
{
    "Paper_ID": 7,
    "Paper_Title": "Adapt or Get Left Behind:Domain Adaptation through BERT Language Model Fine tuning for Aspect-Target Sentiment Classification",
    "Background": "The article presents a novel approach to domain adaptation for Aspect-Based Sentiment Analysis (ABSA) using BERT language model fine tuning, achieving state-of-the-art performance and providing insights through a case study on model prediction errors.",
    "Scope": "The articles focus on using BERT models for Aspect-Based Sentiment Analysis (ABSA), including domain adaptation, model robustness evaluation, and input reduction methods, highlighting their applications in e-commerce and other domains within Natural Language Processing research.",
    "Approach": "Methods include two-step ATSC approach with domain-specific BERT fine tuning, cross-domain evaluation, and input reduction for model interpretation.",
    "Model": "BERT, BERT BASE, BERT-ADA, XLNet",
    "Dataset": "SemEval 2014 Task 4 restaurants dataset, Laptops dataset, Restaurants dataset",
    "Result": "State-of-the-art results on SemEval 2014 restaurants dataset. Limits of language model fine tuning explored. Input reduction method for interpreting model errors. Challenges in aspect-target sentiment classification addressed. Insights from case study on model errors provided."
}
{
    "Paper_ID": 8,
    "Paper_Title": "Mask and Infill: Applying Masked Language Model to Sentiment Transfer",
    "Background": "The paper introduces 'Mask and Infill', for sentiment transfer, using a bidirectional Masked Language Model to separate style from content and infill masked positions with context-conditioned words. Outperforms RNN-based methods in sentiment attribute modification.",
    "Scope": "Sentiment transfer, text infilling, and natural language generation tasks benefit from the masked language model approach introduced in the article.",
    "Approach": "The article proposes Mask and Infill for sentiment transfer. It masks sentimental tokens to separate style from content, then uses a bidirectional Masked Language Model to infill masked positions, improving sentiment transfer performance.",
    "Model": "CrossAligned, StyleEmbedding and MultiDecoder, CycledReinforce, TemplateBased, RetrievalOnly, DeleteOnly, and DeleteAndRetrieval, LM Classifer",
    "Dataset": "SemEval 2014 Task 4 restaurants dataset, Laptops dataset",
    "Result": "The article demonstrates state-of-the-art sentiment classification through BERT fine tuning, addressing challenges and suggesting future directions."
}
{
    "Paper_ID": 9,
    "Paper_Title": "Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence",
    "Background": "The article proposes sentence-pair classification for ABSA, leveraging BERT's fine-tuning, achieving state-of-the-art results, and advocating for its applicability to other tasks.",
    "Scope": "The article's ABSA method using BERT has broad applications in sentiment analysis across domains, enhancing accuracy and efficiency for tasks like product reviews, customer feedback, and social media sentiment analysis.",
    "Approach": "The article proposes converting ABSA into sentence-pair classification using BERT fine-tuning, ",
    "Model": "BERT",
    "Dataset": "SentiHood dataset, SemEval-2014 Task 4 dataset",
    "Result": "the article demonstrates the effectiveness of using BERT and the conversion of ABSA into a sentence pair classification task for achieving improved results in aspect-based sentiment analysis."
}
{
    "Paper_ID": 10,
    "Paper_Title": "BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis",
    "Background": "Article introduces Review Reading Comprehension (RRC) using customer reviews, enhances BERT with post-training, addresses annotation challenges, and emphasizes e-commerce QA importance.",
    "Scope": "Article focuses on e-commerce Review Reading Comprehension (RRC), introduces ReviewRC dataset, proposes BERT post-training, addresses annotation challenges, and emphasizes task-awareness.",
    "Approach": "Article proposes BERT post-training for RRC, introduces ReviewRC dataset, addresses annotation challenges, emphasizes task-awareness, and highlights e-commerce QA importance.",
    "Model": "BERT-LSTM, BERT-Attention, BERT-PT-LSTM, BERT-PT-Attention, BERT-PT, BERTBASE, ELMo, GPT, and BERT",
    "Dataset": "The article mentions ABSA datasets such as Restaurant reviews, Laptop reviews, and the ACL 14 Twitter dataset. It also mentions the SNLI dataset for natural language inference (NLI) tasks.",
    "Result": "The results of the article include the effectiveness of utilizing intermediate layers, improved performance in ABSA and NLI tasks, and the comparison of different models."
}
{
    "Paper_ID": 11,
    "Paper_Title": "BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis",
    "Background": "Article suggests BERT post-training to improve e-commerce Review Reading Comprehension (RRC), using ReviewRC dataset, addressing BERT's limitations.",
    "Scope": "Article proposes BERT post-training to enhance e-commerce Review Reading Comprehension. It introduces ReviewRC dataset and discusses BERT's limitations.",
    "Approach": "Article proposes post-training BERT for RRC and review tasks. It introduces ReviewRC dataset, addresses BERT limitations, and emphasizes using customer reviews for e-commerce decision-making.",
    "Model": "BERT",
    "Dataset": "Article uses ReviewRC, SemEval 2016 Task 5 (laptop and restaurant reviews), SemEval 2014 Task 4, and SemEval 2016 Task 5 (laptops and restaurants) datasets",
    "Result": "Post-training BERT enhances RRC and other tasks like aspect extraction/classification. ReviewRC-trained RRC model shows promising results. Emphasizes BERT's adaptability for ABSA."
}
{
    "Paper_ID": 12,
    "Paper_Title": "Utilizing BERT Intermediate Layers for Aspect Based Sentiment Analysis and Natural Language Inference",
    "Background": "Article explores BERT intermediate layers for ABSA and NLI tasks, proposing BERT-LSTM and BERT-Attention models. Achieves state-of-the-art ABSA results and enhances NLI.",
    "Scope": "Article explores enhancing BERT with intermediate layers for ABSA and NLI, demonstrating state-of-the-art results and comparing with vanilla BERT and other models.",
    "Approach": "The article presents BERT-LSTM and BERT-Attention models for ABSA and NLI tasks, leveraging intermediate layers with LSTM-Pooling and Attention-Pooling. These models outperform previous methods, demonstrating the significance of utilizing intermediate representations.",
    "Model": "BERT-LSTM, BERT-Attention, Vanilla BERT, Other BERT-based models, pytorch-pretrained-BERT:",
    "Dataset": "The article uses ABSA datasets: SemEval 2014 Task 4 (Restaurant, Laptop) and ACL 14 Twitter, also SNLI dataset for NLI tasks, with random dev set selection.",
    "Result": "The article enhances BERT for ABSA and NLI tasks, achieving state-of-the-art results on ABSA datasets and demonstrating effectiveness on NLI. BERT-LSTM and BERT-Attention models outperform vanilla BERT, validated with 10-fold cross-validation and SNLI dataset testing."
}
{
    "Paper_ID": 13,
    "Paper_Title": "Exploiting BERT for End-to-End Aspect-based Sentiment Analysis",
    "Background": "Article explores BERT for E2E-ABSA, outperforming baselines. Highlights dev set importance. Addresses ABSA model limitations, aided by grant support.",
    "Scope": "Article explores BERT for E2E-ABSA, surpassing baselines. Stresses dev set use, offers benchmark. Discusses ABSA limitations, backed by grant, contributes to sentiment analysis field.",
    "Approach": "Article utilizes BERT for E2E-ABSA, comparing with baselines, stressing dev set. Techniques include linear classification, self-attention, GRU. Supported by grant, addresses ABSA limitations.",
    "Model": "BERT",
    "Dataset": "SemEval, REST dataset and LAPTOP dataset, ",
    "Result": "Experimental results demonstrate BERT's superiority in E2E-ABSA, showcasing robustness, effectiveness, and potential for real-world applications."
}
{
    "Paper_ID": 14,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
// Named Entity Recognition
{
    "Paper_ID": 15,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 16,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 17,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 18,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 19,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 21,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 22,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 23,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 24,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 25,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 26,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 27,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 28,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 29,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 30,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 31,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 32,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 33,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}
{
    "Paper_ID": 34,
    "Paper_Title": "",
    "Background": "",
    "Scope": "",
    "Approach": "",
    "Model": "",
    "Dataset": "",
    "Result": ""
}